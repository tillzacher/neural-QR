{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64fbcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A QR code, cleverly embedded into a ancient ice cave, neon-lit theme, pixel art, 3D rendered\n",
      "ancient_ice_cave_pixel_art_neon_lit\n"
     ]
    }
   ],
   "source": [
    "from modules.input_gen import generate_prompt, generate_wifi_qr_string\n",
    "\n",
    "prompt, filename = generate_prompt()\n",
    "print(prompt)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76404740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIFI:S:Zacher;T:WPA;P:warwisch2;;\n"
     ]
    }
   ],
   "source": [
    "message = 'https://www.linkedin.com/in/till-zacher/'\n",
    "message = generate_wifi_qr_string('Zacher', 'warwisch2')\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0999ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.qr_code_gen import generate_qr_code, add_noise_to_qr_code\n",
    "\n",
    "border = 10\n",
    "mask_logo = 10\n",
    "clean_qr = generate_qr_code(message, border=border, mask_logo=mask_logo)\n",
    "\n",
    "center_noise_level = 1\n",
    "noise_level = 0.5\n",
    "border_noise_level = 1\n",
    "noisy_qr = add_noise_to_qr_code(clean_qr, noise_level=noise_level, border_noise_level=border_noise_level, center_noise_level=center_noise_level, mask_logo=mask_logo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d918903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.diffuser import resize_for_condition_image\n",
    "\n",
    "resize_for_condition_image(noisy_qr, resolution=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40507ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: secret chamber inside an ice cave\n",
      "Filename: secret_chamber_inside_an_ice_cave\n",
      "Running qr code diffusion with prompt: secret chamber inside an ice cave\n",
      "Using MPS device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]An error occurred while trying to fetch models/animerge_v23/vae: Error no file named diffusion_pytorch_model.safetensors found in directory models/animerge_v23/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch models/animerge_v23/unet: Error no file named diffusion_pytorch_model.safetensors found in directory models/animerge_v23/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00,  6.96it/s]/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 13.50it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted colors of the images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7/90 [00:12<02:27,  1.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m num_inference_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     29\u001b[0m verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mrun_diffusion_on_qr_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mborder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mborder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_logo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_logo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter_noise_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter_noise_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mborder_noise_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mborder_noise_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvert_colors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrolnet_conditioning_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrolnet_conditioning_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/qr_code/modules/diffuser.py:178\u001b[0m, in \u001b[0;36mrun_diffusion_on_qr_code\u001b[0;34m(message, prompt, filename, border, mask_logo, center_noise_level, noise_level, border_noise_level, model_id, controlnet_model_id, resolution, seed, invert_colors, guidance_scale, controlnet_conditioning_scale, strength, num_inference_steps, verbose)\u001b[0m\n\u001b[1;32m    175\u001b[0m     generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator(device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Generate the image.\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnegative_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mugly, disfigured, low quality, blurry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrolnet_conditioning_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrolnet_conditioning_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m final_image \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    193\u001b[0m final_image\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_images/temp/latest_diffused.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/diffusers/pipelines/controlnet/pipeline_controlnet_img2img.py:1269\u001b[0m, in \u001b[0;36mStableDiffusionControlNetImg2ImgPipeline.__call__\u001b[0;34m(self, prompt, image, control_image, height, width, strength, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, controlnet_conditioning_scale, guess_mode, control_guidance_start, control_guidance_end, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     mid_block_res_sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mzeros_like(mid_block_res_sample), mid_block_res_sample])\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;66;03m# predict the noise residual\u001b[39;00m\n\u001b[0;32m-> 1269\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdown_block_additional_residuals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdown_block_res_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmid_block_additional_residual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmid_block_res_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# perform guidance\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_classifier_free_guidance:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/diffusers/models/unets/unet_2d_condition.py:1214\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_adapter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(down_intrablock_additional_residuals) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1212\u001b[0m         additional_residuals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_residuals\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m down_intrablock_additional_residuals\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m-> 1214\u001b[0m     sample, res_samples \u001b[38;5;241m=\u001b[39m \u001b[43mdownsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1224\u001b[0m     sample, res_samples \u001b[38;5;241m=\u001b[39m downsample_block(hidden_states\u001b[38;5;241m=\u001b[39msample, temb\u001b[38;5;241m=\u001b[39memb)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/diffusers/models/unets/unet_2d_blocks.py:1270\u001b[0m, in \u001b[0;36mCrossAttnDownBlock2D.forward\u001b[0;34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs, encoder_attention_mask, additional_residuals)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1269\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m resnet(hidden_states, temb)\n\u001b[0;32m-> 1270\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;66;03m# apply additional residuals to the output of the last pair of resnet and attention blocks\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m additional_residuals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:427\u001b[0m, in \u001b[0;36mTransformer2DModel.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, timestep, added_cond_kwargs, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m    416\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    417\u001b[0m             block,\n\u001b[1;32m    418\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m             class_labels,\n\u001b[1;32m    425\u001b[0m         )\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# 3. Output\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_input_continuous:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/diffusers/models/attention.py:539\u001b[0m, in \u001b[0;36mBasicTransformerBlock.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels, added_cond_kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m     norm_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(hidden_states, timestep)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mada_norm_zero\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_norm_i2vgen\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 539\u001b[0m     norm_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mada_norm_single\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# For PixArt norm2 isn't applied here:\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;66;03m# https://github.com/PixArt-alpha/PixArt-alpha/blob/0f55e922376d8b797edd44d25d0e7464b260dcab/diffusion/model/nets/PixArtMS.py#L70C1-L76C103\u001b[39;00m\n\u001b[1;32m    543\u001b[0m     norm_hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/modules/normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_mps_env/lib/python3.10/site-packages/torch/nn/functional.py:2910\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2902\u001b[0m         layer_norm,\n\u001b[1;32m   2903\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2908\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2909\u001b[0m     )\n\u001b[0;32m-> 2910\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from modules.diffuser import run_diffusion_on_qr_code\n",
    "from modules.input_gen import generate_prompt\n",
    "\n",
    "message = 'https://www.linkedin.com/in/till-zacher/'\n",
    "prompt, filename = generate_prompt()\n",
    "prompt_override = 'secret chamber inside an ice cave'\n",
    "if prompt_override:\n",
    "    prompt = prompt_override\n",
    "    filename = prompt.replace(' ', '_')\n",
    "\n",
    "print(f'Prompt: {prompt}')\n",
    "print(f'Filename: {filename}')\n",
    "border = 10\n",
    "mask_logo = 4\n",
    "\n",
    "center_noise_level = 0.6\n",
    "noise_level = 0.6\n",
    "border_noise_level = 0.3\n",
    "\n",
    "model_id = 'models/animerge_v23'\n",
    "resolution = 512\n",
    "seed = 384\n",
    "\n",
    "invert_colors = True\n",
    "guidance_scale = 7\n",
    "controlnet_conditioning_scale=1.2\n",
    "strength=0.9\n",
    "num_inference_steps=100\n",
    "verbose=True\n",
    "\n",
    "run_diffusion_on_qr_code(\n",
    "    message,\n",
    "    prompt,\n",
    "    filename,\n",
    "    border=border,\n",
    "    mask_logo=mask_logo,\n",
    "    center_noise_level=center_noise_level,\n",
    "    noise_level=noise_level,\n",
    "    border_noise_level=border_noise_level,\n",
    "    model_id=model_id,\n",
    "    resolution=resolution,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    seed=seed,\n",
    "    invert_colors=invert_colors,\n",
    "    guidance_scale=guidance_scale,\n",
    "    controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
    "    strength=strength,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ae1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mps_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
